{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f00a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float: left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float: left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dea7fe",
   "metadata": {},
   "source": [
    "# Semesterarbeit Statistische Datenanalyse\n",
    "\n",
    "## Dokumenteninformationen\n",
    "\n",
    "\n",
    "| Titel   <img width=200/> |      todo     |\n",
    "|:---------|:------------- |\n",
    "| Schule |  Fernfachhochschule Schweiz |\n",
    "| Studiengang |    Certificate of Advanced Studies in Statistische Datenanalyse & Datenvisualisierung   |\n",
    "| Kennung | DS-C-SD002.StatDa.ZH-Sa-1.PVA.FS23 |\n",
    "| Semester | Frühlingssemester 2023 |\n",
    "| Dozent | **Peter Tellenbach**<br>peter.tellenbach@ffhs.ch<br> |\n",
    "| Autor | **Patrick Hirschi**<br>Geburtsdatum: 12.01.1990<br>Matrikelnummer: 10-179-026<br>Studierenden-ID: 200768<br>patrick-hirschi@gmx.ch<br> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaefb64",
   "metadata": {},
   "source": [
    "## Datenbeschaffung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05871657",
   "metadata": {},
   "source": [
    "### Nutzungsbedingungen\n",
    "\n",
    "Sehr wichtig ist, dass die Nutzungsbedingungen der Datensets beachtet werden. Es gibt verschiedene Kategorien:\n",
    "  * **OPEN** (offen für alle Zwecke, Quellenangabe empfohlen)\n",
    "  * **OPEN BY** (offen für alle Zwecke, Quellenangabe verpflichtend)\n",
    "  * **OPEN ASK** (nicht-kommerziell OK, kommerziell muss erfragt werden beim Datenlieferanten, Quellenangabe empfohlen)\n",
    "  * **OPEN BY ASK** (nicht-kommerziell OK, kommerziell muss erfragt werden beim Datenlieferanten, Quellenangabe verpflichtend)\n",
    "  \n",
    "Sämtliche für dieses Projekt verwendeten Datensets sind in der Kategorie **OPEN** und stammen alle von derselben Quelle ([opendata.swiss](https://opendata.swiss/de/dataset/stundlich-aktualisierte-luftqualitatsmessungen-seit-19831))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69dc23dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib: 3.6.3\n",
      "requests: 2.28.2\n",
      "pandas: 1.5.3\n",
      "numpy: 1.24.2\n",
      "plotly: 5.13.0\n",
      "The module import was successful!\n"
     ]
    }
   ],
   "source": [
    "# import required modules\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import plotly \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# print versions\n",
    "print('matplotlib: %s' % matplotlib.__version__)\n",
    "print('requests: %s' % requests.__version__)\n",
    "print('pandas: %s' % pd.__version__)\n",
    "print('numpy: %s' % np.__version__)\n",
    "print('plotly: %s' % plotly.__version__)\n",
    "\n",
    "# log success\n",
    "print(f'The module import was successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df636429",
   "metadata": {},
   "source": [
    "### Konfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb231c",
   "metadata": {},
   "source": [
    "Die Daten sind über URLs eindeutig beschrieben, und können so einfach neu heruntergeladen werden. Der Export ist konfigurierbar und kann auch ausgeschalten werden. Bei jedem Export werden die bereits vorhandenen Datenfiles mit einem Zeitstempel versehen und archiviert. Dies garantiert die vollständige Reproduzierbarkeit.\n",
    "  \n",
    "Wenn zusätzliche Datenfiles von opendata.swiss geladen werden sollen, so können die entsprechenden URLs und Filenamen ganz einfach dazukonfiguriert werden, und der Code fürs Laden der Daten muss nicht weiter angefasst werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5af7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to True for reloading data or switch to False if wanting to skip \n",
    "# the reload and work with the existing data\n",
    "download_new_source_data = False\n",
    "# assign directory\n",
    "directory = './data'\n",
    "# get current datetime\n",
    "datetime_now = datetime.datetime.now()\n",
    "# base url\n",
    "base_url = 'https://data.stadt-zuerich.ch/dataset/ugz_luftschadstoffmessung_stundenwerte/download/'\n",
    "# start year\n",
    "start_year = 1983\n",
    "# end year\n",
    "end_year = 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca1b0c",
   "metadata": {},
   "source": [
    "### Laden der Daten von opendata.swiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26971d",
   "metadata": {},
   "source": [
    "Wenn ein (neues) Laden der Daten konfiguriert wurde, wird in einem ersten Schritt aufgeräumt. Alle vorhandenen Datenfiles im ./data Verzeichnis werden dann ins ./data/archive Verzeichnis verschoben.\n",
    "  \n",
    "Das python requests Modul ermöglicht es mit nur einer Zeile den entsprechenden Datensatz herunterzuladen. In der Folge wird das neue File im lokalen Filesystem erstellt.\n",
    "  \n",
    "Ein selektives Neuladen von nur einzelnen Files ist nicht vorgesehen, wäre aber mit paar wenigen Code-Anpassungen möglich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdde3f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:12:31.319201: No data was reloaded from source! If this was not intended, change the switch download_new_source_data to True.\n"
     ]
    }
   ],
   "source": [
    "# datetime method for logging purposes\n",
    "def get_current_time_str():\n",
    "    return datetime.datetime.now().strftime(\"%H:%M:%S.%f\")\n",
    "\n",
    "# only execute this code if the switch \"download_new_source_data\" is set to true\n",
    "if download_new_source_data:\n",
    "    # iterate over old data files in the directory and archive in ./data/archive folder\n",
    "    for file in os.listdir(directory):\n",
    "        # join the filepath information\n",
    "        fullpath = os.path.join(directory, file)\n",
    "        # split the filepath into filename and fileextension\n",
    "        filename = os.path.splitext(file)[0]\n",
    "        fileextension = os.path.splitext(file)[1]\n",
    "        # generate a datestring to add to the archived filename\n",
    "        datestring = datetime_now.strftime(\"%Y%m%d%H%M%S\") + '_'\n",
    "        # checking if it is a CSV/XLSX file to avoid archiving non-data files\n",
    "        if os.path.isfile(fullpath) and (fullpath.endswith('.csv') or fullpath.endswith('.xlsx')):\n",
    "            print(f'{get_current_time_str()}: Found file with path: {fullpath}')\n",
    "            # generate archive filename\n",
    "            newpath = directory + '/archive/' + datestring + filename + fileextension\n",
    "            print(f'{get_current_time_str()}: Archive filepath will be: {newpath}')\n",
    "            # rename the file and move it directly to the archive directory\n",
    "            os.rename(fullpath,newpath)\n",
    "            print(f'{get_current_time_str()}: Successfully archived file {fullpath}'\n",
    "                  f' to {newpath}!') \n",
    "            \n",
    "    # download latest data files from opendata.swiss\n",
    "    for x in range(start_year, end_year+1):\n",
    "        try:\n",
    "            # build url\n",
    "            url = base_url + f'ugz_ogd_air_h1_{str(x)}.csv'\n",
    "            # access the data file url\n",
    "            response = requests.get(url, allow_redirects=True)          \n",
    "            # write content to the target file\n",
    "            open(os.path.join(directory, f'ugz_ogd_air_h1_{str(x)}.csv'), 'wb').write(response.content)          \n",
    "            # get file stats\n",
    "            file_stats = os.stat(os.path.join(directory, f'ugz_ogd_air_h1_{str(x)}.csv'))\n",
    "            # If the response was successful, no Exception will be raised\n",
    "            response.raise_for_status()\n",
    "        except HTTPError as http_err:\n",
    "            # log the details of the HTTP exception (specific catch)\n",
    "            print(f'{get_current_time_str()}: HTTP error occurred while' \n",
    "                  f'downloading data file {key} from {url}: {err}') \n",
    "        except Exception as err:\n",
    "            # log the details of any other exception (generic catch)\n",
    "            print(f'{get_current_time_str()}: Other error occurred while'\n",
    "                  f'downloading data file {key} from {url}: {err}')  \n",
    "        else:\n",
    "            # download and file write was succesful\n",
    "            print(f'{get_current_time_str()}: Successfully loaded '\n",
    "                  f'{file_stats.st_size} bytes from {url} into the data file ugz_ogd_air_h1_{str(x)}.csv!') \n",
    "else:\n",
    "    # source data was intentionally not re-loaded\n",
    "    print(f'{get_current_time_str()}: '\n",
    "          f'No data was reloaded from source! If this was not intended, change the switch '\n",
    "          f'download_new_source_data to True.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8b13b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CSV files list from a folder\n",
    "csv_files = glob.glob(directory + \"/*.csv\")\n",
    "\n",
    "# Read each CSV file into DataFrame\n",
    "# This creates a list of dataframes\n",
    "df_list = (pd.read_csv(file) for file in csv_files)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df_air_quality = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b214fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datum</th>\n",
       "      <th>Standort</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Intervall</th>\n",
       "      <th>Einheit</th>\n",
       "      <th>Wert</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987-01-01T03:00+0100</td>\n",
       "      <td>Zch_Stampfenbachstrasse</td>\n",
       "      <td>CO</td>\n",
       "      <td>h1</td>\n",
       "      <td>mg/m3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>bereinigt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987-01-01T03:00+0100</td>\n",
       "      <td>Zch_Stampfenbachstrasse</td>\n",
       "      <td>NO2</td>\n",
       "      <td>h1</td>\n",
       "      <td>µg/m3</td>\n",
       "      <td>33.42</td>\n",
       "      <td>bereinigt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987-01-01T03:00+0100</td>\n",
       "      <td>Zch_Stampfenbachstrasse</td>\n",
       "      <td>NO</td>\n",
       "      <td>h1</td>\n",
       "      <td>µg/m3</td>\n",
       "      <td>6.18</td>\n",
       "      <td>bereinigt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987-01-01T03:00+0100</td>\n",
       "      <td>Zch_Stampfenbachstrasse</td>\n",
       "      <td>NOx</td>\n",
       "      <td>h1</td>\n",
       "      <td>ppb</td>\n",
       "      <td>22.43</td>\n",
       "      <td>bereinigt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987-01-01T03:00+0100</td>\n",
       "      <td>Zch_Stampfenbachstrasse</td>\n",
       "      <td>O3</td>\n",
       "      <td>h1</td>\n",
       "      <td>µg/m3</td>\n",
       "      <td>39.90</td>\n",
       "      <td>bereinigt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datum                 Standort Parameter Intervall Einheit  \\\n",
       "0  1987-01-01T03:00+0100  Zch_Stampfenbachstrasse        CO        h1   mg/m3   \n",
       "1  1987-01-01T03:00+0100  Zch_Stampfenbachstrasse       NO2        h1   µg/m3   \n",
       "2  1987-01-01T03:00+0100  Zch_Stampfenbachstrasse        NO        h1   µg/m3   \n",
       "3  1987-01-01T03:00+0100  Zch_Stampfenbachstrasse       NOx        h1     ppb   \n",
       "4  1987-01-01T03:00+0100  Zch_Stampfenbachstrasse        O3        h1   µg/m3   \n",
       "\n",
       "    Wert     Status  \n",
       "0   0.10  bereinigt  \n",
       "1  33.42  bereinigt  \n",
       "2   6.18  bereinigt  \n",
       "3  22.43  bereinigt  \n",
       "4  39.90  bereinigt  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air_quality.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4500b3a0",
   "metadata": {},
   "source": [
    "## Datenaufbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00be1c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Zch_Stampfenbachstrasse', 'Zch_Schimmelstrasse',\n",
       "       'Zch_Heubeeribüel', 'Zch_Rosengartenstrasse'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air_quality.Standort.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e66920f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bereinigt', 'provisorisch'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air_quality.Status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "375a94d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['h1'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air_quality.Intervall.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e589252d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CO', 'NO2', 'NO', 'NOx', 'O3', 'SO2', 'PM10', 'PM2.5'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_air_quality.Parameter.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0edf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statda-sem",
   "language": "python",
   "name": "statda-sem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
